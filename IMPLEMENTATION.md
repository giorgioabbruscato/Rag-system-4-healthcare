# Sistema RAG Healthcare - Riepilogo Implementazione

## âœ… Implementato

### 1. Auto-indexing Dataset
- **Script**: `scripts/build_dataset.py`
- **Input**: 16 file DICOM in `data/raw_data/` (4 categorie diagnostiche)
- **Output**: 
  - `data/dataset_built/documents.jsonl` (176 documenti)
  - `data/dataset_built/labels.csv` (mapping caseâ†’diagnosis)
  - `data/dataset_built/images/` (160 frame PNG estratti, 10/caso)
- **Esecuzione**: automatica al primo avvio via `start.sh`, oppure manuale con `./rebuild_dataset.sh`

### 2. Vectorstore Manager (Singleton)
- **File**: `src/vectorstore_manager.py`
- **Caratteristiche**:
  - Qdrant in-memory (configurabile per server remoto)
  - Auto-indexing al primo utilizzo
  - Embedding locale: SentenceTransformer all-MiniLM-L6-v2 (384 dim)
  - Collection:
    - `cases`: 16 case cards (metadata + features estratte)
    - `guidelines`: 9 chunk da 3 file guideline
  - UUID deterministici per ID documenti
  - Gestione errori e logging

### 3. Backend FastAPI
- **File**: `api/main.py`
- **Endpoint**:
  - `POST /chat`: query RAG (cases, guidelines, hybrid, multimodal)
  - `POST /upload-doc`: upload DICOM ed estrazione frame
  - `GET /list-docs`: lista documenti caricati
  - `POST /delete-doc`: rimuovi documento
  - `POST /flush-rag`: reset soft del sistema
- **CORS**: abilitato per sviluppo locale
- **Docs**: Swagger UI su http://localhost:8000/docs

### 4. RAG Service
- **File**: `api/services/rag_service.py`
- **FunzionalitÃ **:
  - Retrieval semantico da vectorstore
  - Supporto per rag_type: cases, guidelines, hybrid
  - Ritorna answer + sources con metadata
  - Preparato per integrazione multimodale

### 5. Script di Avvio
- **File**: `start.sh` (eseguibile)
- **Flusso**:
  1. Verifica/crea ambiente virtuale
  2. Installa dipendenze da requirements.txt
  3. **Build dataset da DICOM** (se non esiste)
  4. Check OPENAI_API_KEY
  5. Inizializza vectorstore (auto-indexing)
  6. Avvia FastAPI backend (uvicorn, hot-reload)

### 6. Documentazione
- **README.md**: overview architettura + quick start
- **QUICKSTART.md**: guida API dettagliata con esempi curl
- **rebuild_dataset.sh**: script per rigenerare dataset

## ğŸ“Š Dati Indicizzati

### Cases (16 documenti)
- **Normal**: 10 casi
- **Normal with septal hypertrophy**: 1 caso
- **Dilated cardiomyopathy with global dysfunction**: 1 caso
- **Inferoapical septal akinesia**: 4 casi

### Guidelines (9 chunk)
- `dilated_cardiomyopathy_background.txt`
- `inferoapical_akinesia_background.txt`
- `normal_echo_background.txt`

### Metadata Estratte da DICOM
- View, Stage, FPS, Durata effettiva, Heart rate
- Numero frame, Dimensioni, Photometric interpretation
- **Feature calcolate**:
  - `mean_intensity`: intensitÃ  media normalizzata
  - `motion_energy`: energia del movimento (diff frame consecutivi)
  - `motion_std`: deviazione standard movimento

## ğŸš€ Come Usare

### Avvio Rapido
```bash
export OPENAI_API_KEY="sk-..."
./start.sh
```

### Test API
```bash
# Query RAG sui casi
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What are the characteristics of dilated cardiomyopathy?",
    "model": "gpt-4o",
    "rag_type": "cases",
    "evaluate": false
  }'

# Risposta include:
# - answer: testo generato (stub)
# - sources: array con case/guideline recuperati
# - session_id: per conversazioni
```

### Rigenerare Dataset
```bash
# Se aggiungi nuovi DICOM in data/raw_data/
./rebuild_dataset.sh
# Poi riavvia il backend per re-indexing
```

## ğŸ”§ Configurazione

### Passare a Qdrant Remoto
1. Avvia Qdrant server:
   ```bash
   docker run -d -p 6333:6333 qdrant/qdrant
   ```

2. Modifica `src/vectorstore_manager.py` riga 27:
   ```python
   _vectorstore = QdrantVectorstore(host="localhost", port=6333)
   ```

3. Riavvia backend

### Variabili d'Ambiente
- `OPENAI_API_KEY`: richiesta per LLM (obbligatoria)
- `QDRANT_HOST`: host Qdrant server (default: localhost)
- `QDRANT_PORT`: porta Qdrant (default: 6333)
- `USE_REMOTE_QDRANT`: "true" per usare server remoto (implementabile)

## ğŸ“ Struttura Completa

```
Rag-system-4-healthcare/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                         # FastAPI app (CORS, endpoints)
â”‚   â””â”€â”€ services/
â”‚       â”œâ”€â”€ doc_service.py              # Upload DICOM, list/delete docs
â”‚       â””â”€â”€ rag_service.py              # RAG query logic + retrieval
â”œâ”€â”€ app/
â”‚   â””â”€â”€ streamlit_app.py                # Frontend (WIP)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw_data/                       # DICOM originali (INPUT)
â”‚   â”‚   â”œâ”€â”€ Normal/                     # 10 file .dcm
â”‚   â”‚   â”œâ”€â”€ Normal_with_septal_hypertrophy/  # 1 file
â”‚   â”‚   â”œâ”€â”€ dilated_cardiomyopathy_with_global_dysfunction/  # 1 file
â”‚   â”‚   â””â”€â”€ inferoapical_septal_akinesia/    # 4 file
â”‚   â”œâ”€â”€ dataset_built/                  # AUTO-GENERATO
â”‚   â”‚   â”œâ”€â”€ documents.jsonl             # 176 documenti (16 cases + 160 frames)
â”‚   â”‚   â”œâ”€â”€ labels.csv                  # Case ID â†’ Label mapping
â”‚   â”‚   â””â”€â”€ images/                     # Frame estratti (10 per caso)
â”‚   â”‚       â”œâ”€â”€ <case_id_1>/
â”‚   â”‚       â”‚   â”œâ”€â”€ frame_1.png ... frame_10.png
â”‚   â”‚       â””â”€â”€ ...
â”‚   â””â”€â”€ guidelines_txt/                 # Linee guida (INPUT)
â”‚       â”œâ”€â”€ dilated_cardiomyopathy_background.txt
â”‚       â”œâ”€â”€ inferoapical_akinesia_background.txt
â”‚       â””â”€â”€ normal_echo_background.txt
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ build_dataset.py                # DICOM â†’ documents.jsonl (pipeline completa)
â”‚   â”œâ”€â”€ dicom_to_frames_current.py      # Estrazione frame singolo caso
â”‚   â”œâ”€â”€ multimodal_rag_openai.py        # Pipeline RAG multimodale
â”‚   â”œâ”€â”€ index_Qdrant.py                 # Indexing manuale (legacy, non piÃ¹ usato)
â”‚   â”œâ”€â”€ index_guidelines.py             # Indexing manuale guidelines (legacy)
â”‚   â”œâ”€â”€ query_retrieval.py              # Test retrieval (legacy)
â”‚   â””â”€â”€ eval_hitk_mrr.py                # Evaluation metrics (WIP)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vectorstore_manager.py          # â­ Singleton Qdrant + auto-indexing
â”œâ”€â”€ .venv/                              # Ambiente virtuale Python
â”œâ”€â”€ requirements.txt                    # Dipendenze
â”œâ”€â”€ start.sh                            # â­ Script avvio completo (eseguibile)
â”œâ”€â”€ rebuild_dataset.sh                  # â­ Rigenera dataset (eseguibile)
â”œâ”€â”€ README.md                           # Overview progetto
â”œâ”€â”€ QUICKSTART.md                       # Guida API + esempi
â””â”€â”€ LICENSE
```

## ğŸ”„ Workflow Completo

```
[DICOM files in raw_data/]
         â†“
    build_dataset.py
         â†“
    documents.jsonl + images/
         â†“
    vectorstore_manager.py (auto-indexing)
         â†“
    Qdrant collections (cases + guidelines)
         â†“
    rag_service.py (retrieval)
         â†“
    FastAPI /chat endpoint
         â†“
    [Response con answer + sources]
```

## ğŸ¯ Prossimi Step

### PrioritÃ  Alta
- [ ] Integrare `multimodal_rag_openai.py` completamente in `rag_service.py`
- [ ] Implementare gestione frame del caso corrente in upload-doc
- [ ] Aggiungere chiamata effettiva a OpenAI GPT-4o (attualmente stub)

### PrioritÃ  Media
- [ ] Implementare sessioni/conversazioni con memoria
- [ ] Aggiungere metriche evaluation (ragas)
- [ ] Completare frontend Streamlit
- [ ] Logging strutturato (JSON)

### PrioritÃ  Bassa
- [ ] Passare a Qdrant persistente (Docker)
- [ ] Caching risposte
- [ ] Rate limiting API
- [ ] Autenticazione/autorizzazione

## ğŸ› Known Issues

1. **Ricerca semantica casi**: attualmente recupera casi "Normal" anche per query su patologie (embedding troppo generico per metadata, serve prompt engineering o fine-tuning)
2. **OpenAI call**: stub, non ancora integrata la chiamata vera
3. **Session management**: non implementato (session_id ignorato)
4. **Evaluation**: metriche non collegate

## ğŸ’¡ Note Tecniche

- **UUID deterministici**: usiamo `uuid.uuid5` con namespace DNS per generare ID riproducibili da case_id/guideline_id
- **DenseEmbedding**: datapizza richiede oggetti `DenseEmbedding(name, vector)`, non dict/list
- **Chunk API**: `QdrantVectorstore.add()` accetta `Chunk` objects, non parametri separati
- **Search results**: ritorna lista di `Chunk`, non oggetti con `.score` (score Ã¨ interno)
- **Embedding dimensioni**: 384 per all-MiniLM-L6-v2 (non 1536 di OpenAI)

## ğŸ“ Supporto

Per problemi o domande:
1. Controlla i log del backend (stdout di uvicorn)
2. Verifica che documents.jsonl esista e non sia vuoto
3. Testa vectorstore manualmente: `python3 src/vectorstore_manager.py`
4. Controlla che OPENAI_API_KEY sia settata
